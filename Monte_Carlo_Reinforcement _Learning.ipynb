{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning-Monte Carlo-Exploring with start state-Greedt approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing required Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Start=S\n",
    "#Goal=G(End)\n",
    "#W=Wall(Cannot pass)\n",
    "#X=way(You can pass)\n",
    "#Grid = np.zeros(shape=(6,6))\n",
    "Grid=np.array([['X','X','W','X','X','X'],\n",
    "     ['X','S','X','X','X','X'],\n",
    "     ['X','X','X','W','X','X'],\n",
    "     ['X','W','X','X','X','X'],\n",
    "     ['X','X','X','X','W','X'],\n",
    "     ['X','X','X','X','G','X']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width & Height  : 6 6\n",
      "Start Postion  : (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Get the dimensions of the map and Start postion in this case start positon is predefined as per the algorithm\n",
    "width = Grid.shape[0]\n",
    "height = Grid.shape[1]\n",
    "print(\"Width & Height  :\",width,height)\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if Grid[i][j]=='S':\n",
    "            start=(i,j)\n",
    "print(\"Start Postion  :\",start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 1\n",
      "(0, 1) 1\n",
      "(0, 2) -1\n",
      "(0, 3) 1\n",
      "(0, 4) 1\n",
      "(0, 5) 1\n",
      "(1, 0) 1\n",
      "(1, 1) 1\n",
      "(1, 2) 1\n",
      "(1, 3) 1\n",
      "(1, 4) 1\n",
      "(1, 5) 1\n",
      "(2, 0) 1\n",
      "(2, 1) 1\n",
      "(2, 2) 1\n",
      "(2, 3) -1\n",
      "(2, 4) 1\n",
      "(2, 5) 1\n",
      "(3, 0) 1\n",
      "(3, 1) -1\n",
      "(3, 2) 1\n",
      "(3, 3) 1\n",
      "(3, 4) 1\n",
      "(3, 5) 1\n",
      "(4, 0) 1\n",
      "(4, 1) 1\n",
      "(4, 2) 1\n",
      "(4, 3) 1\n",
      "(4, 4) -1\n",
      "(4, 5) 1\n",
      "(5, 0) 1\n",
      "(5, 1) 1\n",
      "(5, 2) 1\n",
      "(5, 3) 1\n",
      "(5, 4) 1\n",
      "(5, 5) 1\n",
      "(0, 0) ['R', 'D']\n",
      "(0, 1) ['R', 'D', 'L']\n",
      "(0, 2) ['R', 'D', 'L']\n",
      "(0, 3) ['R', 'D', 'L']\n",
      "(0, 4) ['R', 'D', 'L']\n",
      "(0, 5) ['D', 'L']\n",
      "(1, 0) ['U', 'R', 'D']\n",
      "(1, 1) ['U', 'R', 'D', 'L']\n",
      "(1, 2) ['U', 'R', 'D', 'L']\n",
      "(1, 3) ['U', 'R', 'D', 'L']\n",
      "(1, 4) ['U', 'R', 'D', 'L']\n",
      "(1, 5) ['U', 'D', 'L']\n",
      "(2, 0) ['U', 'R', 'D']\n",
      "(2, 1) ['U', 'R', 'D', 'L']\n",
      "(2, 2) ['U', 'R', 'D', 'L']\n",
      "(2, 3) ['U', 'R', 'D', 'L']\n",
      "(2, 4) ['U', 'R', 'D', 'L']\n",
      "(2, 5) ['U', 'D', 'L']\n",
      "(3, 0) ['U', 'R', 'D']\n",
      "(3, 1) ['U', 'R', 'D', 'L']\n",
      "(3, 2) ['U', 'R', 'D', 'L']\n",
      "(3, 3) ['U', 'R', 'D', 'L']\n",
      "(3, 4) ['U', 'R', 'D', 'L']\n",
      "(3, 5) ['U', 'D', 'L']\n",
      "(4, 0) ['U', 'R', 'D']\n",
      "(4, 1) ['U', 'R', 'D', 'L']\n",
      "(4, 2) ['U', 'R', 'D', 'L']\n",
      "(4, 3) ['U', 'R', 'D', 'L']\n",
      "(4, 4) ['U', 'R', 'D', 'L']\n",
      "(4, 5) ['U', 'D', 'L']\n",
      "(5, 0) ['U', 'R']\n",
      "(5, 1) ['U', 'R', 'L']\n",
      "(5, 2) ['U', 'R', 'L']\n",
      "(5, 3) ['U', 'R', 'L']\n",
      "(5, 4) ['U', 'R', 'L']\n",
      "(5, 5) ['U', 'L']\n"
     ]
    }
   ],
   "source": [
    "# rewards should be a dict of: (row, col): reward\n",
    "# actions should be a dict of: (row, col): list of possible actions to move agent\n",
    "rewards={}\n",
    "actions={}\n",
    "#Set rewards\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if Grid[i][j]=='W':\n",
    "            rewards[(i,j)]=-1\n",
    "        else:\n",
    "            rewards[(i,j)]=1\n",
    "for k,v in rewards.items():\n",
    "    print(k,v)\n",
    "#set actions at each state\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if i==0:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['R','D']\n",
    "            elif j== width-1:\n",
    "                actions[(i,j)]=['D','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['R','D','L']\n",
    "        if i>0 and i<height-1:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['U','R','D']\n",
    "            elif j==width-1:\n",
    "                actions[(i,j)]=['U','D','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['U','R','D','L']\n",
    "        if i== height-1:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['U','R']\n",
    "            elif j== width-1:\n",
    "                actions[(i,j)]=['U','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['U','R','L']\n",
    "for k,v in actions.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ['U', 'D', 'L', 'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy:\n",
      "------------------------------------\n",
      "  D  |  L  |  D  |  D  |  R  |  L  |\n",
      "------------------------------------\n",
      "  R  |  L  |  U  |  D  |  L  |  D  |\n",
      "------------------------------------\n",
      "  D  |  R  |  U  |  R  |  U  |  U  |\n",
      "------------------------------------\n",
      "  R  |  R  |  R  |  L  |  R  |  U  |\n",
      "------------------------------------\n",
      "  R  |  L  |  R  |  D  |  R  |  L  |\n",
      "------------------------------------\n",
      "  U  |  L  |  L  |  R  |  R  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# state -> action\n",
    "# initialize a random policy\n",
    "policy = {}\n",
    "for state in actions.keys():\n",
    "    policy[state] = np.random.choice(actions[state])\n",
    "# initial policy\n",
    "\n",
    "def print_policy(P, g):\n",
    "  for i in range(width):\n",
    "    print(\"------------------------------------\")\n",
    "    for j in range(height):\n",
    "        a = P[(i,j)]\n",
    "        print(\"  %s  |\" % a, end=\"\")\n",
    "    print(\"\")\n",
    "print(\"initial policy:\")\n",
    "print_policy(policy, Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): {'R': 0, 'D': 0}, (0, 1): {'R': 0, 'D': 0, 'L': 0}, (0, 2): {'R': 0, 'D': 0, 'L': 0}, (0, 3): {'R': 0, 'D': 0, 'L': 0}, (0, 4): {'R': 0, 'D': 0, 'L': 0}, (0, 5): {'D': 0, 'L': 0}, (1, 0): {'U': 0, 'R': 0, 'D': 0}, (1, 1): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (1, 2): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (1, 3): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (1, 4): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (1, 5): {'U': 0, 'D': 0, 'L': 0}, (2, 0): {'U': 0, 'R': 0, 'D': 0}, (2, 1): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (2, 2): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (2, 3): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (2, 4): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (2, 5): {'U': 0, 'D': 0, 'L': 0}, (3, 0): {'U': 0, 'R': 0, 'D': 0}, (3, 1): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (3, 2): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (3, 3): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (3, 4): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (3, 5): {'U': 0, 'D': 0, 'L': 0}, (4, 0): {'U': 0, 'R': 0, 'D': 0}, (4, 1): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (4, 2): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (4, 3): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (4, 4): {'U': 0, 'R': 0, 'D': 0, 'L': 0}, (4, 5): {'U': 0, 'D': 0, 'L': 0}, (5, 0): {'U': 0, 'R': 0}, (5, 1): {'U': 0, 'R': 0, 'L': 0}, (5, 2): {'U': 0, 'R': 0, 'L': 0}, (5, 3): {'U': 0, 'R': 0, 'L': 0}, (5, 4): {'U': 0, 'R': 0, 'L': 0}, (5, 5): {'U': 0, 'L': 0}}\n"
     ]
    }
   ],
   "source": [
    "# initialize Q(s,a) and returns\n",
    "Q = {}\n",
    "returns = {} # dictionary of state -> list of returns we've received\n",
    "states = actions.keys()\n",
    "ALL_POSSIBLE_ACTIONS = ['U', 'D', 'L', 'R']\n",
    "for s in states:\n",
    "  if s in actions.keys(): # not a terminal state\n",
    "    Q[s] = {}\n",
    "    for a in actions[s]:\n",
    "      Q[s][a] = 0\n",
    "      returns[(s,a)] = []\n",
    "  else:\n",
    "    # terminal state or state we can't otherwise get to\n",
    "    pass\n",
    "  \n",
    "# initial Q values for all states in grid\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_action(s, eps=0.1):\n",
    "    # with probability 1 - eps \n",
    "    a=policy[s]\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(actions[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'L'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0d174b3bc473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mstates_actions_returns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we want it to be in order of state visited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstates_actions_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-0d174b3bc473>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(Grid, policy)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the next state is stochastic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mstates_actions_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-b34ef47a7690>\u001b[0m in \u001b[0;36mrandom_action\u001b[0;34m(s, eps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# with probability 1 - eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'L'"
     ]
    }
   ],
   "source": [
    "def move(action,i,j):\n",
    "    # check if legal move first\n",
    "    if action in actions[(i,j)]:\n",
    "      if action == 'U':\n",
    "        i -= 1\n",
    "      elif action == 'D':\n",
    "        i += 1\n",
    "      elif action == 'R':\n",
    "        j += 1\n",
    "      elif action == 'L':\n",
    "        j -= 1\n",
    "    # return a reward (if any)\n",
    "    return (rewards[(i,j)],i,j)\n",
    "\n",
    "\n",
    "def play_game(Grid, policy):\n",
    "  # returns a list of states and corresponding returns\n",
    "  # use an epsilon-soft policy\n",
    "    s=start\n",
    "    a = random_action(s)\n",
    "    # each triple is s(t), a(t), r(t)\n",
    "    # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "    states_actions_rewards = [(s, a, 0)]\n",
    "    while True:\n",
    "        r,x,y = move(a,s[0],s[1])\n",
    "        if Grid[x][y]=='G':\n",
    "            states_actions_rewards.append((s, None, r))\n",
    "            break\n",
    "        else:\n",
    "            a = random_action(policy[s]) # the next state is stochastic\n",
    "            states_actions_rewards.append((s, a, r))\n",
    " \n",
    "  # calculate the returns by working backwards from the terminal state\n",
    "        G = 0\n",
    "        states_actions_returns = []\n",
    "        first = True\n",
    "    for s, a, r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s, a, G))\n",
    "            G = r + GAMMA*G\n",
    "    states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "    return states_actions_returns\n",
    "play_game(Grid, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
