{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning-Monte Carlo-Exploring with start state-Greedt approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing required Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Start=S\n",
    "#Goal=G(End)\n",
    "#W=Wall(Cannot pass)\n",
    "#X=way(You can pass)\n",
    "#Grid = np.zeros(shape=(6,6))\n",
    "Grid=np.array([['X','X','W','X','X','X'],\n",
    "     ['X','S','X','X','X','X'],\n",
    "     ['X','X','X','W','X','X'],\n",
    "     ['X','W','X','X','X','X'],\n",
    "     ['X','X','X','X','W','X'],\n",
    "     ['X','X','X','X','G','X']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width & Height  : 6 6\n",
      "Start Postion  : (1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Get the dimensions of the map and Start postion in this case start positon is predefined as per the algorithm\n",
    "width = Grid.shape[0]\n",
    "height = Grid.shape[1]\n",
    "print(\"Width & Height  :\",width,height)\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if Grid[i][j]=='S':\n",
    "            start=(i,j)\n",
    "print(\"Start Postion  :\",start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 1\n",
      "(0, 1) 1\n",
      "(0, 2) -1\n",
      "(0, 3) 1\n",
      "(0, 4) 1\n",
      "(0, 5) 1\n",
      "(1, 0) 1\n",
      "(1, 1) 1\n",
      "(1, 2) 1\n",
      "(1, 3) 1\n",
      "(1, 4) 1\n",
      "(1, 5) 1\n",
      "(2, 0) 1\n",
      "(2, 1) 1\n",
      "(2, 2) 1\n",
      "(2, 3) -1\n",
      "(2, 4) 1\n",
      "(2, 5) 1\n",
      "(3, 0) 1\n",
      "(3, 1) -1\n",
      "(3, 2) 1\n",
      "(3, 3) 1\n",
      "(3, 4) 1\n",
      "(3, 5) 1\n",
      "(4, 0) 1\n",
      "(4, 1) 1\n",
      "(4, 2) 1\n",
      "(4, 3) 1\n",
      "(4, 4) -1\n",
      "(4, 5) 1\n",
      "(5, 0) 1\n",
      "(5, 1) 1\n",
      "(5, 2) 1\n",
      "(5, 3) 1\n",
      "(5, 4) 1\n",
      "(5, 5) 1\n",
      "(0, 0) ['R', 'D']\n",
      "(0, 1) ['R', 'D', 'L']\n",
      "(0, 2) ['R', 'D', 'L']\n",
      "(0, 3) ['R', 'D', 'L']\n",
      "(0, 4) ['R', 'D', 'L']\n",
      "(0, 5) ['D', 'L']\n",
      "(1, 0) ['U', 'R', 'D']\n",
      "(1, 1) ['U', 'R', 'D', 'L']\n",
      "(1, 2) ['U', 'R', 'D', 'L']\n",
      "(1, 3) ['U', 'R', 'D', 'L']\n",
      "(1, 4) ['U', 'R', 'D', 'L']\n",
      "(1, 5) ['U', 'D', 'L']\n",
      "(2, 0) ['U', 'R', 'D']\n",
      "(2, 1) ['U', 'R', 'D', 'L']\n",
      "(2, 2) ['U', 'R', 'D', 'L']\n",
      "(2, 3) ['U', 'R', 'D', 'L']\n",
      "(2, 4) ['U', 'R', 'D', 'L']\n",
      "(2, 5) ['U', 'D', 'L']\n",
      "(3, 0) ['U', 'R', 'D']\n",
      "(3, 1) ['U', 'R', 'D', 'L']\n",
      "(3, 2) ['U', 'R', 'D', 'L']\n",
      "(3, 3) ['U', 'R', 'D', 'L']\n",
      "(3, 4) ['U', 'R', 'D', 'L']\n",
      "(3, 5) ['U', 'D', 'L']\n",
      "(4, 0) ['U', 'R', 'D']\n",
      "(4, 1) ['U', 'R', 'D', 'L']\n",
      "(4, 2) ['U', 'R', 'D', 'L']\n",
      "(4, 3) ['U', 'R', 'D', 'L']\n",
      "(4, 4) ['U', 'R', 'D', 'L']\n",
      "(4, 5) ['U', 'D', 'L']\n",
      "(5, 0) ['U', 'R']\n",
      "(5, 1) ['U', 'R', 'L']\n",
      "(5, 2) ['U', 'R', 'L']\n",
      "(5, 3) ['U', 'R', 'L']\n",
      "(5, 4) ['U', 'R', 'L']\n",
      "(5, 5) ['U', 'L']\n"
     ]
    }
   ],
   "source": [
    "# rewards should be a dict of: (row, col): reward\n",
    "# actions should be a dict of: (row, col): list of possible actions to move agent\n",
    "rewards={}\n",
    "actions={}\n",
    "#Set rewards\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if Grid[i][j]=='W':\n",
    "            rewards[(i,j)]=-1\n",
    "        else:\n",
    "            rewards[(i,j)]=1\n",
    "for k,v in rewards.items():\n",
    "    print(k,v)\n",
    "#set actions at each state\n",
    "for i  in range(width):\n",
    "    for j in range(height):\n",
    "        if i==0:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['R','D']\n",
    "            elif j== width-1:\n",
    "                actions[(i,j)]=['D','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['R','D','L']\n",
    "        if i>0 and i<height-1:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['U','R','D']\n",
    "            elif j==width-1:\n",
    "                actions[(i,j)]=['U','D','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['U','R','D','L']\n",
    "        if i== height-1:\n",
    "            if j==0:\n",
    "                actions[(i,j)]=['U','R']\n",
    "            elif j== width-1:\n",
    "                actions[(i,j)]=['U','L']\n",
    "            else:\n",
    "                actions[(i,j)]=['U','R','L']\n",
    "for k,v in actions.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ['U', 'D', 'L', 'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy:\n",
      "------------------------------------\n",
      "  D  |  L  |  L  |  U  |  R  |  D  |\n",
      "------------------------------------\n",
      "  R  |  R  |  R  |  R  |  L  |  L  |\n",
      "------------------------------------\n",
      "  L  |  R  |  U  |  L  |  L  |  R  |\n",
      "------------------------------------\n",
      "  R  |  D  |  L  |  D  |  U  |  D  |\n",
      "------------------------------------\n",
      "  L  |  D  |  L  |  L  |  R  |  L  |\n",
      "------------------------------------\n",
      "  D  |  R  |  U  |  D  |  U  |  D  |\n"
     ]
    }
   ],
   "source": [
    "# state -> action\n",
    "# initialize a random policy\n",
    "policy = {}\n",
    "for state in actions.keys():\n",
    "    policy[state] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "# initial policy\n",
    "\n",
    "def print_policy(P, g):\n",
    "    for i in range(width):\n",
    "        print(\"------------------------------------\")\n",
    "        for j in range(height):\n",
    "            a = P[(i,j)]\n",
    "            print(\"  %s  |\" % a, end=\"\")\n",
    "        print(\"\")\n",
    "print(\"initial policy:\")\n",
    "print_policy(policy, Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (0, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (1, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (2, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (3, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (4, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 0): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 1): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 2): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 3): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 4): {'U': 0, 'D': 0, 'L': 0, 'R': 0}, (5, 5): {'U': 0, 'D': 0, 'L': 0, 'R': 0}}\n"
     ]
    }
   ],
   "source": [
    "# initial Q values for all states in grid\n",
    "# initialize Q(s,a) and returns\n",
    "Q = {}\n",
    "returns = {} # dictionary of state -> list of returns we've received\n",
    "states = actions.keys()\n",
    "for s in states:\n",
    "    if s in actions.keys(): # not a terminal state\n",
    "        Q[s] = {}\n",
    "        for a in ALL_POSSIBLE_ACTIONS:\n",
    "            Q[s][a] = 0\n",
    "            returns[(s,a)] = []\n",
    "    else:\n",
    "    # terminal state or state we can't otherwise get to\n",
    "        pass\n",
    "print(Q)\n",
    "#Q learning values initiallization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_action(s, eps=0.01):\n",
    "    # with probability 1 - eps \n",
    "    a=policy[s]\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "# returns the maximun values from dictionary\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def move(action,i,j):\n",
    "    # check if move exists\n",
    "    if action in actions[(i,j)]:\n",
    "        if action == 'U':\n",
    "            i -= 1\n",
    "        elif action == 'D':\n",
    "            i += 1\n",
    "        elif action == 'R':\n",
    "            j += 1\n",
    "        elif action == 'L':\n",
    "            j -= 1\n",
    "    # return a reward associated with move\n",
    "    return (rewards[(i,j)],i,j)\n",
    "\n",
    "\n",
    "def play_game(Grid, policy,start):\n",
    "# returns a list of states and corresponding returns\n",
    "  # use an epsilon-soft policy\n",
    "    s=start\n",
    "    a = random_action(s)\n",
    "    # each triple is s(t), a(t), r(t)\n",
    "    # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "    states_actions_rewards = [(s, a, 0)]\n",
    "    while True:\n",
    "        r,x,y = move(a,s[0],s[1])\n",
    "        s =(x,y)\n",
    "        if Grid[x][y]=='G':\n",
    "            states_actions_rewards.append((s, None, r))\n",
    "            break\n",
    "        else:\n",
    "            a = random_action(s) # the next state is stochastic\n",
    "            states_actions_rewards.append((s, a, r))\n",
    " \n",
    "  # calculate the returns by working backwards from the terminal state\n",
    "        G = 0\n",
    "        states_actions_returns = []\n",
    "        first = True\n",
    "    for s, a, r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s, a, G))\n",
    "            G = r + GAMMA*G\n",
    "    states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "    return states_actions_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat\n",
    "deltas = []\n",
    "for t in range(50):\n",
    "# generate an episode using pi\n",
    "    biggest_change = 0\n",
    "    states_actions_returns = play_game(Grid, policy,start)\n",
    "\n",
    "# calculate Q(s,a)\n",
    "    seen_state_action_pairs = set()\n",
    "    for s, a, G in states_actions_returns:\n",
    "    # check if we have already seen s\n",
    "    # called \"first-visit\" MC policy evaluation\n",
    "        sa = (s, a)\n",
    "        if sa not in seen_state_action_pairs:\n",
    "            old_q = Q[s][a]\n",
    "            returns[sa].append(G)\n",
    "            Q[s][a] = np.mean(returns[sa])\n",
    "            biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "            seen_state_action_pairs.add(sa)\n",
    "    deltas.append(biggest_change)\n",
    "# calculate new policy pi(s) = argmax[a]{ Q(s,a) }\n",
    "    for s in policy.keys():\n",
    "        a, _ = max_dict(Q[s])\n",
    "        policy[s] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116efc940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 10.00| 10.00| 10.00|\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 10.00| 10.00| 10.00|\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 10.00| 10.00| 10.00|\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 9.99| 10.00| 10.00|\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 10.00| 10.00| 10.00|\n",
      "---------------------------\n",
      " 10.00| 10.00| 10.00| 10.00| 0.00| 10.00|\n"
     ]
    }
   ],
   "source": [
    "def print_values(V, g):\n",
    "    for i in range(width):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(height):\n",
    "            v = V.get((i,j), 0)\n",
    "            if v >= 0:\n",
    "                print(\" %.2f|\" % v, end=\"\")\n",
    "            else:\n",
    "                print(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
    "        print(\"\")\n",
    "# find the optimal state-value function\n",
    "# V(s) = max[a]{ Q(s,a) }\n",
    "V = {}\n",
    "for s in policy.keys():\n",
    "    V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "print(\"final values:\")\n",
    "print_values(V, Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final policy:\n",
      "------------------------------------\n",
      "  R  |  U  |  R  |  D  |  U  |  U  |\n",
      "------------------------------------\n",
      "  D  |  L  |  R  |  R  |  R  |  R  |\n",
      "------------------------------------\n",
      "  D  |  U  |  U  |  U  |  U  |  R  |\n",
      "------------------------------------\n",
      "  D  |  U  |  D  |  D  |  R  |  R  |\n",
      "------------------------------------\n",
      "  D  |  L  |  D  |  L  |  L  |  R  |\n",
      "------------------------------------\n",
      "  U  |  D  |  D  |  U  |  U  |  U  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final policy:\")\n",
    "print_policy(policy, Grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
